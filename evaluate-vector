#!/usr/bin/env python
import argparse # optparse is deprecated
import numpy as np
from VectorMap import VectorMap
import string
from itertools import islice # slicing for iterators
import progressbar
from time import sleep
 
 # unneeded, replace with cosign similarity calculations
def word_matches(h, ref):
    return sum(1 for w in h if w in ref)

def euclidean_dist(sent_vec, ref_vec):
    return (sum((x[0] - x[1]) ** 2 for x in zip(sent_vec, ref_vec))) ** 0.5

def sentence_similarity(sent_vec, ref_vec):
    dot_product = np.dot(sent_vec, ref_vec)
    mag_sent = np.linalg.norm(sent_vec)
    #print "Sentence Vector: " + str(mag_sent)
    mag_ref = np.linalg.norm(ref_vec)
    #print "Reference Vector: " + str(mag_ref)
    similarity = dot_product / (mag_sent * mag_ref)
    #print "Similarity: " + str(similarity)
    return similarity

def preprocess(line):
    line = line.lower()
    exclude = set(string.punctuation)
    line = ''.join(ch if ch not in exclude else ' ' for ch in line)
    return line
 
def main():
    parser = argparse.ArgumentParser(description='Evaluate translation hypotheses.')
    parser.add_argument('-i', '--input', default='data/hyp1-hyp2-ref',
            help='input file (default data/hyp1-hyp2-ref)')
    parser.add_argument('-n', '--num_sentences', default=None, type=int,
            help='Number of hypothesis pairs to evaluate')
    bar = progressbar.ProgressBar(maxval=20, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])
    # note that if x == [1, 2, 3], then x[:None] == x[:] == x (copy); no need for sys.maxint
    opts = parser.parse_args()
    vm = VectorMap()
    vm.load_from_file("wiki-vectors.txt")
    # we create a generator and avoid loading all sentences into a list
    def sentences():
        with open(opts.input) as f:
            for pair in f:
                yield [preprocess(sentence) for sentence in pair.split(' ||| ')]
# note: the -n option does not work in the original code
    #i = 0
    for h1, h2, ref in islice(sentences(), opts.num_sentences):
        v_ref = vm.sentence_to_vector(ref)
        v_h1 = vm.sentence_to_vector(h1)
        v_h2 = vm.sentence_to_vector(h2)
        h1_match = sentence_similarity(v_h1, v_ref)
        h2_match = sentence_similarity(v_h2, v_ref)
        # 1 if sim between h1 and ref is greater than h2 and ref
        print(1 if h1_match > h2_match else # \begin{cases}
                (0 if h1_match == h2_match
                    else -1)) # \end{cases}
        #bar.update(i+1)
        #i += 1
        #sleep(0.1)
    #bar.finish()
 
# convention to allow import of this file as a module
if __name__ == '__main__':
    main()
